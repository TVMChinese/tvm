# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# a_flying_fish <a_flying_fish@outlook.com>, 2021
# 长德 司, 2021
# HLearning, 2021
# 安杰 许, 2021
# DH Luo, 2021
# juzi, 2021
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev1734+gca660ba1e\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-12 10:06+0000\n"
"PO-Revision-Date: 2021-10-13 01:29+0000\n"
"Last-Translator: juzi, 2021\n"
"Language-Team: Chinese (China) (https://www.transifex.com/TVMChinese/teams/124815/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../_staging/arch/index.rst:19
msgid "Design and Architecture"
msgstr ""

#: ../../_staging/arch/index.rst:21
msgid ""
"This document is intended for developers who want to understand the "
"architecture of TVM and/or actively develop on the project. This page is "
"organized as follows:"
msgstr "本文档适用于想要了解TVM架构和/或积极开发项目的开发人员。本页的布局如下："

#: ../../_staging/arch/index.rst:25
msgid ""
"The `Example Compilation Flow`_ gives an overview of the steps that TVM "
"takes to turn a high level description of a model into a deployable module. "
"To get started, please read this section first."
msgstr "`编译流程示例`_概述了TVM所采取的将一个模型的高层描述转化为一个可部署的模块的步骤。 请从阅读本节开始。"

#: ../../_staging/arch/index.rst:28
msgid ""
"The `Logical Architecture Components`_ section describes the logical "
"components. The sections after are specific guides focused on each logical "
"component, organized by the component's name."
msgstr "`逻辑体系架构组件`_ 章节 描述了逻辑组件。后面的部分按组件的名称，分为每个部件的特定指南。"

#: ../../_staging/arch/index.rst:32
msgid ""
"The :ref:`Device/Target Interactions <tvm-target-specific-overview>` page "
"describes how TVM interacts with each supported physical device and code-"
"generation target."
msgstr ""
" :ref:`Device/Target Interactions <tvm-target-specific-overview>` "
"页面描述了TVM怎样与每个支持的物理设备和代码生成目标进行交互。"

#: ../../_staging/arch/index.rst:36
msgid ""
"Feel free to also check out the :ref:`dev-how-to` for useful development "
"tips."
msgstr "请随意查看 :ref:`开发者指南`以寻求有用的开发技巧"

#: ../../_staging/arch/index.rst:38
msgid ""
"This guide provides a few complementary views of the architecture. First, we"
" review a single end-to-end compilation flow and discuss the key data "
"structures and the transformations. This runtime-based view focuses on the "
"interactions of each components when running the compiler. Then we will "
"review the logical modules of the codebase and their relationship. This part"
" provides a static overarching view of the design."
msgstr ""
"这个指南补充了一些架构的补充视图。首先我们回顾一个单个端到端的编译流程，并讨论关键的数据结构和转换。这个基于runtime的视图，主要关注运行编译器时，各个组件的交互。然后我们会回顾各逻辑模块的基本代码和他们之间的关系。这一部分提供了一个设计的静态的总体视图。"

#: ../../_staging/arch/index.rst:45
msgid "Example Compilation Flow"
msgstr "编译流程示例"

#: ../../_staging/arch/index.rst:47
msgid ""
"In this guide, we will study an example compilation flow in the compiler. "
"The figure below shows the flow. At a high-level, it contains several steps:"
msgstr "本教程中，我们会学习在编译器中的一个编译流程示例。下图展示了这个流程。在高层次上，包含了几个步骤。"

#: ../../_staging/arch/index.rst:49
msgid ""
"Import: The frontend component ingests a model into an IRModule, which "
"contains a collection of functions that internally represent the model."
msgstr "导入：前端组件将模型摄入变成一个IR模块，这个IR模块包含了一批函数，这些函数在内部表示了这个模型。"

#: ../../_staging/arch/index.rst:50
msgid ""
"Transformation: The compiler transforms an IRModule to another functionally "
"equivalent or approximately equivalent(e.g. in the case of quantization) "
"IRModule. Many of the transformations are target (backend) independent. We "
"also allow target to affect the configuration of the transformation "
"pipeline."
msgstr ""
"转换：编译器将一个IR模块转换为另一个在功能上等效或大约等效（例如：在量化情况下）的IR模块。许多转换是独立于目标（即后端）的。我们还允许目标来影响转换pipeline的配置。"

#: ../../_staging/arch/index.rst:53
msgid ""
"Target Translation: The compiler translates(codegen) the IRModule to an "
"executable format specified by the target. The target translation result is "
"encapsulated as a `runtime.Module` that can be exported, loaded, and "
"executed on the target runtime environment."
msgstr ""
"目标转化：编译器将IR模块转化为（codegen）一个可以被目标指定的可执行格式。这个目标转化的结果会被封装成可以在目标runtime环境下被输出，读取和执行的"
" `runtime.Module` 。"

#: ../../_staging/arch/index.rst:55
msgid ""
"Runtime Execution: the user loads back a `runtime.Module` and runs the "
"compiled functions in the supported runtime environment."
msgstr "Runtime执行：用户读回一个 `runtime.Module`并且在支持的runtime环境下运行编译后的函数。"

#: ../../_staging/arch/index.rst:64
msgid "Key data structures"
msgstr "关键数据结构"

#: ../../_staging/arch/index.rst:66
msgid ""
"One of the best ways to design and understand a complex system is to "
"identify the key data structures and APIs that manipulate (transform) these "
"data structures. Once we identified the key data structures, we can then "
"breakdown a system into logical components that either define a collection "
"of key data structures or transformations among the data structures."
msgstr ""
"设计和理解一个复杂系统的最佳方法之一就是去明确关键的数据结构和操纵（转换）这些数据结构的api。一旦我们明确了关键的数据结构，我们就可以将系统拆分为逻辑组件，这些逻辑组件可以定义一批关键数据结构或者定义数据结构之间的转换。"

#: ../../_staging/arch/index.rst:70
msgid ""
"**IRModule** is the primary data structure used across the entire stack. An "
"IRModule (intermediate representation module) contains a collection of "
"functions. Currently, we support two primary variants of functions."
msgstr ""
"**IRModule**是整个堆栈中主要的数据结构。一个IR模块（IRmodule，中间表示模块）包含一组函数。目前我们支持两种主要的函数变体。"

#: ../../_staging/arch/index.rst:73
msgid ""
"**relay::Function** is a high-level functional program representation. A "
"relay.Function usually corresponds to an end-to-end model. You can view a "
"relay.Function as a computational graph with additional support for control-"
"flow, recursion, and complex data structures."
msgstr ""
"**relay::Function** "
"是一种高级函数程序表示。一个relay.Function通常对应一个端到端模型。你可以将relay.Function看作一个计算图，额外带有对控制流，递归和复杂数据结构的支持。"

#: ../../_staging/arch/index.rst:75
msgid ""
"**tir::PrimFunc** is a low-level program representation that contains "
"elements including loop-nest choices, multi-dimensional load/store, "
"threading, and vector/tensor instructions. It is usually used to represent "
"an operator program that executes a (possibly-fused) layer in a model."
msgstr ""
"**tir::PrimFunc** "
"是一种低级程序表示，包含元素，包含循环嵌套选择、多维加载/存储、线程和向量/张量指令等元素。它通常被用于表示在一个模型模型中处理一个（可能融合的）层的算子程序。"

#: ../../_staging/arch/index.rst:78
msgid ""
"During the compilation, a relay function may be lowered to multiple "
"tir::PrimFunc functions and a top-level function that calls into those "
"tir::PrimFunc functions."
msgstr "在编译时，一个relay 函数可能被底层化为多个tir::PrimFunc 函数 和一个调用这些tir::PrimFunc函数的顶层函数。"

#: ../../_staging/arch/index.rst:82
msgid "Transformations"
msgstr "转换"

#: ../../_staging/arch/index.rst:84
msgid ""
"Now that we have covered the key data structures, let us talk about the "
"transformations. Each transformation could serve one of the following "
"purposes:"
msgstr "现在我们已经介绍了关键数据结构，让我们来讨论转换。每个转换都被可用于以下目的之一："

#: ../../_staging/arch/index.rst:86
msgid ""
"optimization: transform a program to an equivalent, possibly more optimized "
"version."
msgstr "优化：将程序转换为一个等效的或者更优化的版本。"

#: ../../_staging/arch/index.rst:87
msgid ""
"lowering: transform a program to a lower-level representation that is closer"
" to the target."
msgstr "底层化：将一个程序转化为更靠近目标，更底层的表达式。"

#: ../../_staging/arch/index.rst:89
msgid ""
"**relay/transform** contains a collection of passes that optimize the model."
" The optimizations include common program optimizations such as constant "
"folding and dead-code elimination, and tensor-computation specific passes "
"such as layout transformation and scaling factor folding."
msgstr ""
"**relay/transform**包含一组优化模型的passes。优化包含常见的程序优化比如常数折叠和死码消除，以及张量特定的passes例如布局转换和比例因子折叠。"

#: ../../_staging/arch/index.rst:93
msgid ""
"Near the end of the relay optimization pipeline, we will run a pass(FuseOps)"
" to break the end-to-end function(e.g. MobileNet) into sub-function(e.g. "
"conv2d-relu) segments. We call these segments of functions. This process "
"helps us to divide the original problem into two sub-problems:"
msgstr ""
"在relay优化pipeline的末尾，我们会运行一个pass（FuseOps）来将端到端函数（例如：MobileNet）拆分为子函数（例如"
"：conv2d-relu）段。我们把这些称为函数段。这个过程帮助我们将原始的问题分为两个子问题。"

#: ../../_staging/arch/index.rst:97
msgid "Compilation and optimization for each sub-function."
msgstr "子函数的编译和优化。"

#: ../../_staging/arch/index.rst:98
msgid ""
"Overall execution structure: we need to do a sequence of calls into the "
"generated sub-functions to execute the whole model."
msgstr "总体执行结构：我们需要对生成的子函数做一系列的调用来执行整个模型。"

#: ../../_staging/arch/index.rst:100
msgid ""
"We use the low-level tir phase to compile and optimize each sub-functions. "
"For specific targets, we may also directly go to the target translation "
"phase and use external code generators."
msgstr "我们用底层tir阶段来编译和优化每个子函数。对特定的目标，我们也可以直接进入目标转化阶段并使用外部代码生成器。"

#: ../../_staging/arch/index.rst:103
msgid ""
"There are a few different ways(in relay/backend) to handle the calls into "
"the overall execution problem. For simple models with known shapes and no "
"control flow, we can lower to a graph executor that stores the execution "
"structure in a graph. We also support a virtual machine backend for dynamic "
"executions. Finally, we plan to support ahead of time compilation that "
"compiles the high-level execution structure into the executable and "
"generated primitive functions. All of these execution modes are encapsulated"
" by a unified **runtime.Module** interface, which we will discuss in the "
"latter part of the guide."
msgstr ""
"有几种不同的方法（在relay/backend）里来处理对整个执行问题的调用。对于具有已知形状且没有控制流的简单模型，我们可以底层化为一个将执行结构存储在图像里的图像执行器。我们也支持用于动态执行的虚拟机后端。最后，我们计划支持提前编译，将高层执行结构编译为可执行的和被生成的原语函数。所有的这些执行模式都被封装在一个同意的"
" **runtime.Module** 接口，我们将在这个指南的后半部分讨论这个接口。"

#: ../../_staging/arch/index.rst:105
msgid ""
"**tir/transform** contains transformation passes for TIR level functions. "
"Many tir passes serve the purpose of lowering. For example, there are passes"
" to flatten multi-dimensional access to one-dimensional pointer access, to "
"expand the intrinsics into target-specific ones, and to decorate the "
"function entry to meet the runtime calling convention. Of course, there are "
"also optimizations passes, such as access index simplification and dead code"
" elimination."
msgstr ""
"**tir/transform**包含TIR层函数的转换passes。很多tir "
"passes的目的是底层化。例如，有些passes将多维访问扁平化为一维指针访问，来内部函数扩展为目标指定函数，以及修饰函数入口来满足runtime调用习惯。当然，也有一些优化passes比如访问索引简化和死码消除。"

#: ../../_staging/arch/index.rst:107
msgid ""
"Many low-level optimizations can be handled in the target phase by the LLVM,"
" CUDA C, and other target compilers. As a result, we leave low-level "
"optimizations such as register allocation to the downstream compilers and "
"only focus on optimizations that are not covered by them."
msgstr ""
"LLVM, CUDA C "
"可以和其他目标编译器可以在目标阶段进行许多底层优化。所以，我们将底层优化如寄存器分配留给下游编译器，而只关注于它们未能涵盖的优化。"

#: ../../_staging/arch/index.rst:110
msgid "Search-space and Learning-based Transformations"
msgstr "搜索空间和基于学习的转换"

#: ../../_staging/arch/index.rst:112
msgid ""
"The transformation passes we described so far are deterministic and rule-"
"based. One design goal of the TVM stack is to support high-performance code "
"optimizations for different hardware platforms. To do so, we will need to "
"investigate as many optimization choices as possible, including but not "
"limited to, multi-dimensional tensor access, loop tiling behavior, special "
"accelerator memory hierarchy, and threading."
msgstr ""
"目前为止，我们讨论过的转换过程都是确定和基于规则的。TVM堆栈的一个设计目标就是去支持不同硬件平台上的高性能代码优化。为此，我们需要尽可能多的研究优化的选择，包括但不限于多维张量访问，循环平铺表现，特殊的加速器内存层级和线程。"

#: ../../_staging/arch/index.rst:114
msgid ""
"It is hard to define a heuristic to make all of the choices. Instead, we "
"will take a search and learning-based approach. We first define a collection"
" of actions we can take to transform a program. Example actions include loop"
" transformations, inlining, vectorization. We call these actions "
"**scheduling primitives**. The collection of scheduling primitives defines a"
" search space of possible optimizations we can make to a program. The system"
" then searches over different possible scheduling sequence to pick the best "
"scheduling combination. The search procedure is usually guided by a machine "
"learning algorithm."
msgstr ""
"很难定义一种启发式方法来决定所有的选择。相反，我们将采取基于搜索和学习的方法。我们首先定义一组可以用来转换程序的操作。示例操作包括循环转换、内联、向量化。我们将这些操作称为**调度原语**。调度原语的集合定义了我们可以对程序进行优化的搜索空间。然后，系统搜索不同的可能调度序列来选择最佳调度组合。搜索过程通常由机器学习算法引导。"

#: ../../_staging/arch/index.rst:121
msgid ""
"We can record the best schedule sequence for an (possibly-fused) operator "
"once the search is completed. The compiler can then just lookup the best "
"schedule sequence and apply it to the program. Notably, this schedule "
"application phase is **exactly like** the rule-based transformations, "
"enabling us to share the same interface convention with tradition passes."
msgstr ""
"一旦搜索完成，我们可以为（可能融合的）算子记录最佳调度序列。然后，编译器可以查找最佳调度序列并将其应用于程序。值得注意的是，此调度应用程序阶段与基于规则的转换**完全相同**，使我们能够与传统的passes共享接口协定。"

#: ../../_staging/arch/index.rst:125
msgid ""
"We use search based optimizations to handle the initial tir function "
"generation problem. This part of the module is called "
"AutoTVM(auto_scheduler). We expect to expand the learning-based "
"transformations to more areas as we continue to develop the TVM stack."
msgstr ""
"我们使用基于搜索的优化来处理初始tir函数生成问题。该模块的这一部分称为AutoTVM（自动调度程序）。随着我们继续开发TVM堆栈，我们希望将基于学习的转换扩展到更多领域。"

#: ../../_staging/arch/index.rst:129
msgid "Target Translation"
msgstr "目标转化"

#: ../../_staging/arch/index.rst:131
msgid ""
"The target translation phase transforms an IRModule to the corresponding "
"target executable format. For backends such as x86 and ARM, we use the LLVM "
"IRBuilder to build in-memory LLVM IR. We can also generate source-level "
"languages such as CUDA C and OpenCL. Finally, we support direct translations"
" of a Relay function (sub-graph) to specific targets via external code "
"generators. It is important that the final code generation phase is as "
"lightweight as possible. Vast majority of transformations and lowering "
"should be performed before the target translation phase."
msgstr ""
"目标转换阶段将IRModule转换为对应目标可执行的文件格式。对于x86和ARM等后端，我们使用LLVM IRBuilder构建内存中的LLVM "
"IR。我们还可以生成源代码级语言，如CUDA "
"C和OpenCL。最后，我们支持通过外部代码生成器将Relay函数（子图）直接转化到特定目标。重要的是，最终代码生成阶段应尽可能轻简。绝大多数转换和底层化应在目标转化阶段之前执行。"

#: ../../_staging/arch/index.rst:138
msgid ""
"We also provide a Target structure to specify the compilation target. The "
"transformations before the target translation phase can also be affected by "
"the target — for example, a target's vector length would change the "
"vectorization behavior."
msgstr "我们还提供了一个目标结构来特定编译目标。目标转化阶段之前的变换也会受到目标的影响-例如，目标的向量长度会改变向量化行为。"

#: ../../_staging/arch/index.rst:144
msgid "Runtime Execution"
msgstr "Runtime 执行"

#: ../../_staging/arch/index.rst:146
msgid ""
"The main goal of TVM's runtime is to provide a minimal API for loading and "
"executing the compiled artifact in a language of their choice, including "
"Python, C++, Rust, Go, Java, and JavaScript. The code snippet below shows "
"such an example in Python:"
msgstr ""
"TVM runtime的主要目的是提供一个最小的API用于加载和执行编译后的文件，使用它们选择的语言包括Python，C++，Rust， Go，Java"
" 还有JavaScript。以下的代码片段展示了一个使用Python的例子。"

#: ../../_staging/arch/index.rst:159
msgid ""
":py:class:`tvm.runtime.Module` encapsulates the result of compilation. A "
"runtime.Module contains a GetFunction method to obtain PackedFuncs by name."
msgstr ""
":py:class:`tvm.runtime.Module` 封装了编译的结果。一个runtime.Module 包含一个Getfunction "
"方法来按名称获得PackedFuncs。"

#: ../../_staging/arch/index.rst:161
msgid ""
":py:class:`tvm.runtime.PackedFunc` is a type-erased function interface for "
"both the generated functions. A runtime.PackedFunc can take arguments and "
"return values with the following types: POD types(int, float), string, "
"runtime.PackedFunc, runtime.Module, runtime.NDArray, and other sub-classes "
"of runtime.Object."
msgstr ""
":py:class:`tvm.runtime.PackedFunc`是两种生成函数的类型擦除函数接口。一个 runtime.PackedFunc "
"可以接受参数然后返回以下类型的返回值: POD 类型(int, float), string, runtime.PackedFunc, "
"runtime.Module, runtime.NDArray, 和其他runtime.Object的子类。"

#: ../../_staging/arch/index.rst:164
msgid ""
":py:class:`tvm.runtime.Module` and :py:class:`tvm.runtime.PackedFunc` are "
"powerful mechanisms to modularize the runtime. For example, to get the above"
" `addone` function on CUDA, we can use LLVM to generate the host-side code "
"to compute the launching parameters(e.g. size of the thread groups) and then"
" call into another PackedFunc from a CUDAModule that is backed by the CUDA "
"driver API. The same mechanism can be used for OpenCL kernels."
msgstr ""
":py:class:`tvm.runtime.Module` 和 :py:class:`tvm.runtime.PackedFunc` "
"是模块化runtime的强大机制。 例如, 为了在CUDA得到上述 `addone` 函数,我们可以使用 LLVM "
"来生成主机端代码以计算启动参数(如线程组的大小) "
"然后从CUDA驱动程序API支持的CUDAModule调用另一个PackedFunc。同样的机制也可以用于OpenCL内核。"

#: ../../_staging/arch/index.rst:166
msgid ""
"The above example only deals with a simple `addone` function. The code "
"snippet below gives an example of an end-to-end model execution using the "
"same interface:"
msgstr "上述例子仅仅设计了一个简单的 `addone` 函数。下列的代码片段给了一个端到端模型使用相同接口来执行的例子。"

#: ../../_staging/arch/index.rst:183
msgid ""
"The main take away is that runtime.Module and runtime.PackedFunc are "
"sufficient to encapsulate both operator level programs (such as addone), as "
"well as the end-to-end models."
msgstr ""
"主要结论是，runtime.Module 和 runtime.PackedFunc足够处理算子级别的程序（比如addone）以及端到端模型。"

#: ../../_staging/arch/index.rst:186
msgid "Summary and Discussions"
msgstr "总结与讨论"

#: ../../_staging/arch/index.rst:188
msgid "In summary, the key data structures in the compilation flows are:"
msgstr "总的来说，编译流中的关键数据结构是："

#: ../../_staging/arch/index.rst:190
msgid "IRModule: contains relay.Function and tir.PrimFunc"
msgstr "IRModule: 包含 relay.Function 和 tir.PrimFunc。"

#: ../../_staging/arch/index.rst:191
msgid "runtime.Module: contains runtime.PackedFunc"
msgstr "runtime.Module: 包含 runtime.PackedFunc。"

#: ../../_staging/arch/index.rst:193
msgid ""
"Most parts of the compilation are transformations among the key data "
"structures."
msgstr "编译的大部分流程是关键数据结构之间的转换。"

#: ../../_staging/arch/index.rst:195
msgid ""
"relay/transform and tir/transform are determinstic rule-based "
"transformations"
msgstr "relay/transform 和 tir/transform 是基于规则的确定性转换。"

#: ../../_staging/arch/index.rst:196
msgid "auto_scheduler and autotvm contains the search-based transformations"
msgstr "auto_scheduler 和 autotvm 包含基于搜索的转换。"

#: ../../_staging/arch/index.rst:198
msgid ""
"Finally, the compilation flow example is only a typical use-case of the TVM "
"stack. We expose these key data structures and transformations to python and"
" C++ APIs. As a result, you can use TVM just like the way you use numpy, "
"except that the data structure of interest changes from the numpy.ndarray to"
" tvm.IRModule. Here are some example use-cases:"
msgstr ""
"最后，编译流程示例只是TVM堆栈的一个经典用例。我们将这些关键数据结构和转换提供pyhon和C++API。因此，你可以使用TVM就像使用numpy一样，除了关注的数据结构从numpy.ndarray"
" 变成 tvm.IRModule。一下是一些使用示例。"

#: ../../_staging/arch/index.rst:202
msgid "Directly construct IRModule using the python API."
msgstr "用python API直接构造 IRModule。"

#: ../../_staging/arch/index.rst:203
msgid "Compose a custom set of transformations(e.g. customize quantization)."
msgstr "组成一组自定变换（如自定义量化）。"

#: ../../_staging/arch/index.rst:204
msgid "Manipulate the IR directly using TVM's python API."
msgstr "直接使用TVM提供的python API操作IR。"

#: ../../_staging/arch/index.rst:208
msgid "Logical Architecture Components"
msgstr "逻辑架构组件"

#: ../../_staging/arch/index.rst:214
msgid "TVM Architecture Diagram"
msgstr "TVM体系架构图"

#: ../../_staging/arch/index.rst:216
msgid ""
"The above figure shows the major logical components in the project. Please "
"read the following sections for information about the components and their "
"relations."
msgstr "上方图片展示了项目中的主要逻辑组件。有关组件及其之间关系的信息请阅读接下来的章节。"

#: ../../_staging/arch/index.rst:221
msgid "tvm/support"
msgstr "tvm/support"

#: ../../_staging/arch/index.rst:222
msgid ""
"The support module contains the most common utilities for the "
"infrastructure, such as generic arena allocator, socket, and logging."
msgstr "support 模块包含基础结构最常用的实用程序，例如通用arena分配器，套接字和日志。"

#: ../../_staging/arch/index.rst:226
msgid "tvm/runtime"
msgstr "tvm/runtime"

#: ../../_staging/arch/index.rst:228
msgid ""
"The runtime serves as the foundation of the TVM stack. It provides the "
"mechanism to load and execute compiled artifacts. The runtime defines a "
"stable standard set of C APIs to interface with frontend languages such as "
"Python and Rust."
msgstr ""
"runtime 是 TVM 堆栈的基础。它提供了加载和执行编译文件的机制。runtime给前端语言如 Python 和 Rust，定义了一套稳定的 C "
"API 接口。"

#: ../../_staging/arch/index.rst:231
msgid ""
"`runtime::Object` is one of the primary data structures in TVM runtime "
"besides the `runtime::PackedFunc`. It is a reference-counted base class with"
" a type index to support runtime type checking and downcasting. The object "
"system allows the developer to introduce new data structures to the runtime,"
" such as Array, Map, and new IR data structures."
msgstr ""
"`runtime::Object` 是除了 `runtime::PackedFunc`之外在TVM "
"runtime里面一个重要的数据结构.它是一个引用计数基类，具有类型索引，给runtime类型检查和向下转型提供支持。Object "
"系统允许开发者向runtime引进新的数据结构，比如数组，映射还有新的IR数据结构。"

#: ../../_staging/arch/index.rst:235
msgid ""
"Besides deployment use-cases, the compiler itself also makes heavy use of "
"TVM's runtime mechanism. All of the IR data structures are subclasses of "
"`runtime::Object`, as a result, they can be directly accessed and "
"manipulated from the Python frontend. We use the PackedFunc mechanism to "
"expose various APIs to the frontend."
msgstr ""
"除了部署应用之外，编译器本身还大量使用TVM "
"runtime机制。所有的IR数据结构都是`runtime::Object`的子类，所以它们能直接被python前端直接访问和操作。我们用PackedFunc"
" 机制向前端公开各种API。"

#: ../../_staging/arch/index.rst:239
msgid ""
"Runtime support for different hardware backends are defined in "
"subdirectories of runtime(e.g. runtime/opencl). These hardware-specific "
"runtime modules define APIs for device memory allocation and device function"
" serialization."
msgstr ""
"支持不同硬件后端的runtime在runtime子目录里定义（如runtime/opencl）。这些硬件特定的runtime模块定义了设备内存分配和设备函数的序列化的API。"

#: ../../_staging/arch/index.rst:242
msgid ""
"`runtime/rpc` implements an RPC support for PackedFunc. We can use the RPC "
"mechanism to send a cross-compiled library to a remote device and benchmark "
"the execution performance. The rpc infrastructure enables data collection "
"from a wide range of hardware backends for learning-based optimizations."
msgstr ""
"`runtime/rpc`实现对PackedFunc的rpc支持。我们可以使用RPC机制将交叉编译库发送到远程设备，并对执行性能进行基准测试。rpc基础设施支持从各种硬件后端收集数据，以进行基于学习的优化。"

#: ../../_staging/arch/index.rst:264
msgid "tvm/node"
msgstr "tvm/node"

#: ../../_staging/arch/index.rst:265
msgid ""
"The node module adds additional features on top of the `runtime::Object` for"
" IR data structures. The main features include reflection, serialization, "
"structural equivalence, and hashing."
msgstr "node模块给IR数据结构在 `runtime::Object`之上添加了其他功能。主要功能包括反射、序列化、结构等价和散列。"

#: ../../_staging/arch/index.rst:268
msgid ""
"Thanks to the node module, we can directly access any field of the TVM's "
"IRNode by their name in Python."
msgstr "多亏了node模块，我们可以使用TVM IRNode在python里面的名字来访问它们的任何字段。"

#: ../../_staging/arch/index.rst:279
msgid ""
"We can also serialize arbitrary IR node into a JSON format, and load them "
"back. The ability to save/store, and inspect an IR node provides a "
"foundation for making the compiler more accessible."
msgstr "我们还可以将任意IR node序列化为JSON格式，然后重新加载它们。保存/存储和检查IRnode的能力为编译器更好的可访问性提供了基础。"

#: ../../_staging/arch/index.rst:284
msgid "tvm/ir"
msgstr ""

#: ../../_staging/arch/index.rst:285
msgid ""
"The `tvm/ir` folder contains the unified data structure and interfaces "
"across for all IR function variants. The components in `tvm/ir` are shared "
"by `tvm/relay` and `tvm/tir`, notable ones include"
msgstr ""

#: ../../_staging/arch/index.rst:288
msgid "IRModule"
msgstr ""

#: ../../_staging/arch/index.rst:289
msgid "Type"
msgstr "类型"

#: ../../_staging/arch/index.rst:290
msgid "PassContext and Pass"
msgstr ""

#: ../../_staging/arch/index.rst:291
msgid "Op"
msgstr ""

#: ../../_staging/arch/index.rst:293
msgid ""
"Different variants of functions(e.g. relay.Function and tir.PrimFunc) can "
"co-exist in an IRModule. While these variants may not have the same content "
"representation, they use the same data structure to represent types. As a "
"consequence, we use the same data structure to represent function (type) "
"signatures of these variants. The unified type system allows one function "
"variant to call another function once we clearly define the calling "
"convention. This opens doors for future cross-function-variant "
"optimizations."
msgstr ""

#: ../../_staging/arch/index.rst:299
msgid ""
"We also provide a unified PassContext for configuring the pass behavior, and"
" common composite passes to execute a pass pipeline. The following code "
"snippet gives an example of PassContext configuration."
msgstr ""

#: ../../_staging/arch/index.rst:309
msgid ""
"Op is the common class to represent all system-defined primitive "
"operator/intrinsics. Developers can register new Ops as well as their "
"additional attributes(e.g. whether the Op is elementwise) to the system."
msgstr ""

#: ../../_staging/arch/index.rst:319
msgid "tvm/target"
msgstr "tvm/target"

#: ../../_staging/arch/index.rst:320
msgid ""
"The target module contains all the code generators that translate an "
"IRModule to a target runtime.Module. It also provides a common `Target` "
"class that describes the target."
msgstr ""

#: ../../_staging/arch/index.rst:326
msgid ""
"The compilation pipeline can be customized according to the target by "
"querying the attribute information in the target and builtin information "
"registered to each target id(cuda, opencl)."
msgstr ""

#: ../../_staging/arch/index.rst:335
msgid "tvm/tir"
msgstr "tvm/tir"

#: ../../_staging/arch/index.rst:337
msgid ""
"TIR contains the definition of the low-level program representations. We use"
" `tir::PrimFunc` to represent functions that can be transformed by TIR "
"passes. Besides the IR data structures, the tir module also defines a set of"
" builtin intrinsics and their attributes via the common Op registry, as well"
" as transformation passes in `tir/transform`."
msgstr ""

#: ../../_staging/arch/index.rst:341
msgid "tvm/arith"
msgstr "tvm/arith"

#: ../../_staging/arch/index.rst:343
msgid ""
"This module is closely tied to the TIR. One of the key problems in the low-"
"level code generation is the analysis of the indices' arithmetic properties "
"— the positiveness, variable bound, and the integer set that describes the "
"iterator space. arith module provides a collection of tools that do "
"(primarily integer) analysis. A TIR pass can use these analyses to simplify "
"and optimize the code."
msgstr ""

#: ../../_staging/arch/index.rst:348
msgid "tvm/te"
msgstr "tvm/te"

#: ../../_staging/arch/index.rst:350
msgid ""
"The name te stands for \"tensor expression\". This is a domain-specific "
"language module that allows us to construct `tir::PrimFunc` variants quickly"
" by writing tensor expressions. Importantly, a tensor expression itself is "
"not a self-contained function that can be stored into IRModule. Instead, it "
"is a fragment of IR that we can stitch together to build an IRModule."
msgstr ""

#: ../../_staging/arch/index.rst:353
msgid ""
"`te/schedule` provides a collection of scheduling primitives to control the "
"function being generated. In the future, we might bring some of these "
"scheduling components to the a `tir::PrimFunc` itself."
msgstr ""

#: ../../_staging/arch/index.rst:363
msgid "tvm/topi"
msgstr "tvm/topi"

#: ../../_staging/arch/index.rst:364
msgid ""
"While possible to construct operators directly via TIR or tensor expressions"
" (TE) for each use case it is tedious to do so. `topi` (Tensor operator "
"inventory) provides a set of pre-defined operators (in TE or TIR) defined by"
" numpy and found in common deep learning workloads. We also provide a "
"collection of common schedule templates to obtain performant implementations"
" across different target platforms."
msgstr ""

#: ../../_staging/arch/index.rst:370
msgid "tvm/relay"
msgstr "tvm/relay"

#: ../../_staging/arch/index.rst:371
msgid ""
"Relay is the high-level functional IR used to represent full models. Various"
" optimizations are defined in `relay.transform`. The Relay compiler defines "
"multiple dialects, and each dialect is designed to support specific styles "
"of optimization. Notable ones include QNN(for importing pre-quantized "
"models), VM(for lowering to dynamic virtual machine), memory(for memory "
"optimization)."
msgstr ""

#: ../../_staging/arch/index.rst:384
msgid "tvm/autotvm"
msgstr "tvm/autotvm"

#: ../../_staging/arch/index.rst:386
msgid ""
"AutoTVM and AutoScheduler are both components which automate search based "
"program optimization. This is rapidly evolving and primarily consists of:"
msgstr ""

#: ../../_staging/arch/index.rst:388
msgid "Cost models and feature extraction."
msgstr ""

#: ../../_staging/arch/index.rst:389
msgid ""
"A record format for storing program benchmark results for cost model "
"construction."
msgstr ""

#: ../../_staging/arch/index.rst:390
msgid "A set of search policies over program transformations."
msgstr ""

#: ../../_staging/arch/index.rst:392
msgid ""
"Automated program optimization is still an active research field. As a "
"result, we have attempted to modularize the design so that researchers may "
"quickly modify a component or apply their own algorithms via the Python "
"bindings, and customize the search and plugin their algorithms from the "
"Python binding."
msgstr ""

#: ../../_staging/arch/index.rst:402
msgid "Frontends"
msgstr ""

#: ../../_staging/arch/index.rst:403
msgid ""
"Frontends ingest models from different frameworks into the TVM stack. "
":py:mod:`tvm.relay.frontend` is the namespace for model ingestion APIs."
msgstr ""

#: ../../_staging/arch/index.rst:413
msgid "Security"
msgstr "安全"

#: ../../_staging/arch/index.rst:421
msgid "microTVM"
msgstr "microTVM"
