# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev1734+gca660ba1e\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-12 10:06+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:4
msgid ""
"Click :ref:`here "
"<sphx_glr_download_how_to_deploy_models_deploy_ssd_gluoncv.py>` to "
"download the full example code"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:11
msgid "Deploy Single Shot Multibox Detector(SSD) model"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:12
msgid ""
"**Author**: `Yao Wang <https://github.com/kevinthesun>`_ `Leyuan Wang "
"<https://github.com/Laurawly>`_"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:15
msgid ""
"This article is an introductory tutorial to deploy SSD models with TVM. "
"We will use GluonCV pre-trained SSD model and convert it to Relay IR"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:37
#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:132
msgid "Out:"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:47
msgid "Preliminary and Set parameters"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:50
msgid "We support compiling SSD on both CPUs and GPUs now."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:52
msgid ""
"To get best inference performance on CPU, change target argument "
"according to your device and follow the :ref:`tune_relay_x86` to tune x86"
" CPU and :ref:`tune_relay_arm` for arm CPU."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:57
msgid ""
"To get best inference performance on Intel graphics, change target "
"argument to :code:`opencl -device=intel_graphics`. But when using Intel "
"graphics on Mac, target needs to be set to `opencl` only for the reason "
"that Intel subgroup extension is not supported on Mac."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:63
msgid ""
"To get best inference performance on CUDA-based GPUs, change the target "
"argument to :code:`cuda`; and for OPENCL-based GPUs, change target "
"argument to :code:`opencl` followed by device argument according to your "
"device."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:91
msgid "Download and pre-process demo image"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:110
msgid "Convert and compile model for CPU."
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:142
msgid "Create TVM runtime and do inference .. note::"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:177
msgid "Display result"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:203
msgid "**Total running time of the script:** ( 2 minutes  31.833 seconds)"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:218
msgid ""
":download:`Download Python source code: deploy_ssd_gluoncv.py "
"<deploy_ssd_gluoncv.py>`"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:224
msgid ""
":download:`Download Jupyter notebook: deploy_ssd_gluoncv.ipynb "
"<deploy_ssd_gluoncv.ipynb>`"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_ssd_gluoncv.rst:231
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

