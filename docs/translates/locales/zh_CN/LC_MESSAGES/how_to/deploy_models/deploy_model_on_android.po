# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020 - 2021, Apache Software Foundation
# This file is distributed under the same license as the tvm package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# HLearning, 2021
# jshmsjh, 2021
# juzi, 2021
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: tvm 0.8.dev1734+gca660ba1e\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-12 10:06+0000\n"
"PO-Revision-Date: 2021-10-13 01:32+0000\n"
"Last-Translator: juzi, 2021\n"
"Language-Team: Chinese (China) (https://www.transifex.com/TVMChinese/teams/124815/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:4
msgid ""
"Click :ref:`here "
"<sphx_glr_download_how_to_deploy_models_deploy_model_on_android.py>` to "
"download the full example code"
msgstr ""

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:13
msgid "Deploy the Pretrained Model on Android"
msgstr "在Android上部署预训练模型（Pretrained Model)"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:14
msgid "**Author**: `Tomohiro Kato <https://tkat0.github.io/>`_"
msgstr "**作者**: `Tomohiro Kato <https://tkat0.github.io/>`_"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:16
msgid ""
"This is an example of using Relay to compile a keras model and deploy it on "
"Android device."
msgstr "这是一个使用Relay编译keras模型并将其部署到Android设备上的示例。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:42
msgid "Setup Environment"
msgstr "设置环境"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:43
msgid ""
"Since there are many required packages for Android, it is recommended to use"
" the official Docker Image."
msgstr "由于Android有许多必需的软件包，因此建议使用官方的Docker映像。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:45
msgid ""
"First, to build and run Docker Image, we can run the following command."
msgstr "首先，要构建和运行Docker映像，我们可以运行以下命令。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:55
msgid ""
"You are now inside the container. The cloned TVM directory is mounted on "
"/workspace. At this time, mount the 9190 port used by RPC described later."
msgstr "您现在在容器内。克隆的TVM目录安装在/workspace上。此时，准备一下稍后描述的RPC使用的9190端口。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:60
msgid ""
"Please execute the following steps in the container. We can execute "
":code:`docker exec -it tvm bash` to open a new terminal in the container."
msgstr "请在容器中执行以下步骤。我们可以执行:code:`docker exec -it tvm bash`在容器中打开一个新的终端。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:63
msgid "Next we build the TVM."
msgstr "接下来我们构建 TVM。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:77
msgid "After building TVM successfully, Please set PYTHONPATH."
msgstr "成功构建 TVM 后，请设置 PYTHONPATH。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:85
msgid "Start RPC Tracker"
msgstr "启动 RPC 跟踪器"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:86
msgid "TVM uses RPC session to communicate with Android device."
msgstr "TVM 使用 RPC 会话与安卓设备进行通信。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:88
msgid ""
"To start an RPC tracker, run this command in the container. The tracker is "
"required during the whole tuning process, so we need to open a new terminal "
"for this command:"
msgstr "要启动RPC跟踪器，请在容器中运行此命令。在整个调谐过程中需要跟踪器，因此我们需要为此命令打开一个新的终端："

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:96
msgid "The expected output is"
msgstr "预期输出是"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:103
msgid "Register Android device to RPC Tracker"
msgstr "将安卓设备注册到 RPC 跟踪器"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:104
msgid "Now we can register our Android device to the tracker."
msgstr "现在我们可以将我们的安卓设备注册到跟踪器上。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:106
msgid ""
"Follow this `readme page "
"<https://github.com/apache/tvm/tree/main/apps/android_rpc>`_ to install TVM "
"RPC APK on the android device."
msgstr ""
"请点击`自述页面 "
"<https://github.com/apache/tvm/tree/main/apps/android_rpc>`_在android设备上安装TVM"
" RPC APK。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:109
msgid "Here is an example of config.mk. I enabled OpenCL and Vulkan."
msgstr "下面是config.mk 的例子。我启用了Opencl和Vulkan。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:139
msgid ""
"At this time, don't forget to `create a standalone toolchain "
"<https://github.com/apache/tvm/tree/main/apps/android_rpc#architecture-and-"
"android-standalone-toolchain>`_ ."
msgstr ""
"此时，别忘了`创建一个独立的工具链<https://github.com/apache/tvm/tree/main/apps/android_rpc"
"#architecture-and-android-standalone-toolchain>`_ .。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:141
msgid "for example"
msgstr "例如"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:149
msgid ""
"Next, start the Android application and enter the IP address and port of RPC"
" Tracker. Then you have already registered your device."
msgstr "接下来，启动Android应用程序并输入RPC Tracker的IP地址和端口。然后您就注册好了您的设备。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:152
msgid "After registering devices, we can confirm it by querying rpc_tracker"
msgstr "注册设备后，我们可以通过查询rpc_tracker确认"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:158
msgid "For example, if we have 1 Android device. the output can be"
msgstr "例如，如果我们有 1 个安卓设备。输出是"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:170
msgid ""
"To confirm that you can communicate with Android, we can run following test "
"script. If you use OpenCL and Vulkan, please set :code:`test_opencl` and "
":code:`test_vulkan` in the script."
msgstr ""
"要确认您可以与 Android 通信，我们可以按照测试脚本运行。如果您使用 OpenCL 和 "
"Vulkan，请在脚本中设置:code:`test_opencl` 和:code:`test_vulkan`"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:185
msgid "Load pretrained keras model"
msgstr "加载预训练 Keras 模型"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:186
msgid ""
"We load a pretrained MobileNetV2(alpha=0.5) classification model provided by"
" keras."
msgstr "我们加载keras提供的预先训练过的MobileNetV2(alpha=0.5)分类模型。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:212
msgid ""
"In order to test our model, here we download an image of cat and transform "
"its format."
msgstr "为了测试我们的模型，在这里我们下载了猫的图像，并改变其格式。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:241
msgid ""
"synset is used to transform the label from number of ImageNet class to the "
"word human can understand."
msgstr "synset用于将标签从ImageNet类的数量转换为人类可以理解的单词。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:268
msgid "Compile the model with relay"
msgstr "通过 Realy 编译模型"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:269
msgid ""
"If we run the example on our x86 server for demonstration, we can simply set"
" it as :code:`llvm`. If running it on the Android device, we need to specify"
" its instruction set. Set :code:`local_demo` to False if you want to run "
"this tutorial with a real device."
msgstr ""
"如果我们在x86服务器上运行这个示例进行演示，我们只需将其设置为 "
":code:`llvm`。如果在Android设备上运行它，我们需要指定它的指令集。如果要使用真实设备运行本教程，请将:code:`local_demo`设置为False。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:320
msgid "Deploy the Model Remotely by RPC"
msgstr "通过RPC远程部署模型"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:321
msgid ""
"With RPC, you can deploy the model remotely from your host machine to the "
"remote android device."
msgstr "使用RPC，您可以将模型从主机远程部署到远程android设备。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:362
msgid "Execute on TVM"
msgstr "在 TVM 上执行"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:388
msgid "Out:"
msgstr "输出:"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:402
msgid "Sample Output"
msgstr "样本输出"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:403
msgid ""
"The following is the result of 'cpu', 'opencl' and 'vulkan' using Adreno 530"
" on Snapdragon 820"
msgstr "以下是Snapdragon 820上使用Adreno 530的 'cpu', 'opencl' 和 'vulkan' 的结果"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:405
msgid ""
"Although we can run on a GPU, it is slower than CPU. To speed up, we need to"
" write and optimize the schedule according to the GPU architecture."
msgstr "虽然我们可以在GPU上运行，但它比CPU慢。为了加快速度，我们需要根据GPU架构编写和优化调度。"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:438
msgid ""
":download:`Download Python source code: deploy_model_on_android.py "
"<deploy_model_on_android.py>`"
msgstr ""
":download:`下载 Python 源代码: deploy_model_on_android.py "
"<deploy_model_on_android.py>`"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:444
msgid ""
":download:`Download Jupyter notebook: deploy_model_on_android.ipynb "
"<deploy_model_on_android.ipynb>`"
msgstr ""
":download:`下载 Jupyter notebook: deploy_model_on_android.ipynb "
"<deploy_model_on_android.ipynb>`"

#: ../../_staging/how_to/deploy_models/deploy_model_on_android.rst:451
msgid ""
"`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""
"`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
